{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задаем рабочую папку\n",
    "\n",
    "import os\n",
    "os.chdir(\"C:/Users/Aleksandr/Desktop/CSC/Data Analysis term 2/lab 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        6  \n",
       "1      9.5        6  \n",
       "2     10.1        6  \n",
       "3      9.9        6  \n",
       "4      9.9        6  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Импорт данных\n",
    "wine = pd.read_csv('winequality-white.csv', sep=';', header=0)\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Разделяем предикторы и отклик\n",
    "# Отклик - группирующая переменная -  вектор y\n",
    "y = wine['quality']\n",
    "# Предикторы - таблица X\n",
    "X = wine.drop('quality', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#отклик не сбалансирован"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#запишем все вина 3й категории в 4ю, а 9й  в 8ю (они похожи по качеству)\n",
    "for i in range(1,4897):\n",
    "    if (wine.at[i, 'quality'] == 3):\n",
    "        wine.at[i, 'quality'] = 4\n",
    "    if (wine.at[i, 'quality'] == 9):\n",
    "        wine.at[i, 'quality'] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    0.448755\n",
       "5    0.297468\n",
       "7    0.179665\n",
       "4    0.037362\n",
       "8    0.036750\n",
       "Name: quality, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Отклик сбалансирован? Теперь да\n",
    "wine['quality'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param = {  \n",
    "    'n_estimators': [100], #проверил на 50, 100, 500, 1000, 2000\n",
    "    'max_depth': [8, 10, 15],\n",
    "    'cv': [3], #3 хорошо, проверил на 2, 3, 5, 10\n",
    "    'gamma': [0, 0.1],\n",
    "    'learning_rate': [0.01, 0.1] #проверил на 0.01, 0.1, 0.2\n",
    "    # 'eta' = [0.01, 0.1, 0.2] связана с learning rate\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_grid = GridSearchCV(\n",
    "    error_score='raise',\n",
    "    estimator=XGBClassifier(\n",
    "            seed=42,\n",
    "            eta = 0.2,\n",
    "            n_estimators=1000,\n",
    "            max_depth=4,\n",
    "            learning_rate=0.1,\n",
    "            #base_score=0.5, \n",
    "            #seed=1234, \n",
    "            objective='binary:logistic',\n",
    "            cv=3,\n",
    "            gamma=0, \n",
    "            #learning_rate=0.1, \n",
    "            max_delta_step=0,\n",
    "            min_child_weight=1,\n",
    "            missing=None, \n",
    "            nthread=-1,\n",
    "            #reg_alpha=0, \n",
    "            #reg_lambda=1,\n",
    "            #scale_pos_weight=1, \n",
    "            silent=False,\n",
    "            n_jobs = -1       \n",
    "    ),\n",
    "    #iid=True, \n",
    "    param_grid=grid_param, \n",
    "    #refit=True, \n",
    "    scoring='accuracy', \n",
    "    verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aleksandr\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[CV] cv=3, gamma=0, learning_rate=0.01, max_depth=8, n_estimators=100 \n",
      "[CV]  cv=3, gamma=0, learning_rate=0.01, max_depth=8, n_estimators=100, score=0.605, total=   1.4s\n",
      "[CV] cv=3, gamma=0, learning_rate=0.01, max_depth=8, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cv=3, gamma=0, learning_rate=0.01, max_depth=8, n_estimators=100, score=0.599, total=   1.4s\n",
      "[CV] cv=3, gamma=0, learning_rate=0.01, max_depth=8, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  cv=3, gamma=0, learning_rate=0.01, max_depth=8, n_estimators=100, score=0.567, total=   1.4s\n",
      "[CV] cv=3, gamma=0, learning_rate=0.01, max_depth=10, n_estimators=100 \n",
      "[CV]  cv=3, gamma=0, learning_rate=0.01, max_depth=10, n_estimators=100, score=0.628, total=   1.8s\n",
      "[CV] cv=3, gamma=0, learning_rate=0.01, max_depth=10, n_estimators=100 \n",
      "[CV]  cv=3, gamma=0, learning_rate=0.01, max_depth=10, n_estimators=100, score=0.619, total=   1.7s\n",
      "[CV] cv=3, gamma=0, learning_rate=0.01, max_depth=10, n_estimators=100 \n",
      "[CV]  cv=3, gamma=0, learning_rate=0.01, max_depth=10, n_estimators=100, score=0.569, total=   1.7s\n",
      "[CV] cv=3, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=100 \n",
      "[CV]  cv=3, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=100, score=0.616, total=   2.3s\n",
      "[CV] cv=3, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=100 \n",
      "[CV]  cv=3, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=100, score=0.609, total=   2.4s\n",
      "[CV] cv=3, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=100 \n",
      "[CV]  cv=3, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=100, score=0.571, total=   2.3s\n",
      "[CV] cv=3, gamma=0, learning_rate=0.1, max_depth=8, n_estimators=100 .\n",
      "[CV]  cv=3, gamma=0, learning_rate=0.1, max_depth=8, n_estimators=100, score=0.648, total=   1.3s\n",
      "[CV] cv=3, gamma=0, learning_rate=0.1, max_depth=8, n_estimators=100 .\n",
      "[CV]  cv=3, gamma=0, learning_rate=0.1, max_depth=8, n_estimators=100, score=0.641, total=   1.3s\n",
      "[CV] cv=3, gamma=0, learning_rate=0.1, max_depth=8, n_estimators=100 .\n",
      "[CV]  cv=3, gamma=0, learning_rate=0.1, max_depth=8, n_estimators=100, score=0.588, total=   1.3s\n",
      "[CV] cv=3, gamma=0, learning_rate=0.1, max_depth=10, n_estimators=100 \n",
      "[CV]  cv=3, gamma=0, learning_rate=0.1, max_depth=10, n_estimators=100, score=0.655, total=   1.5s\n",
      "[CV] cv=3, gamma=0, learning_rate=0.1, max_depth=10, n_estimators=100 \n",
      "[CV]  cv=3, gamma=0, learning_rate=0.1, max_depth=10, n_estimators=100, score=0.641, total=   1.6s\n",
      "[CV] cv=3, gamma=0, learning_rate=0.1, max_depth=10, n_estimators=100 \n",
      "[CV]  cv=3, gamma=0, learning_rate=0.1, max_depth=10, n_estimators=100, score=0.594, total=   1.6s\n",
      "[CV] cv=3, gamma=0, learning_rate=0.1, max_depth=15, n_estimators=100 \n",
      "[CV]  cv=3, gamma=0, learning_rate=0.1, max_depth=15, n_estimators=100, score=0.656, total=   2.0s\n",
      "[CV] cv=3, gamma=0, learning_rate=0.1, max_depth=15, n_estimators=100 \n",
      "[CV]  cv=3, gamma=0, learning_rate=0.1, max_depth=15, n_estimators=100, score=0.631, total=   2.0s\n",
      "[CV] cv=3, gamma=0, learning_rate=0.1, max_depth=15, n_estimators=100 \n",
      "[CV]  cv=3, gamma=0, learning_rate=0.1, max_depth=15, n_estimators=100, score=0.592, total=   2.0s\n",
      "[CV] cv=3, gamma=0.1, learning_rate=0.01, max_depth=8, n_estimators=100 \n",
      "[CV]  cv=3, gamma=0.1, learning_rate=0.01, max_depth=8, n_estimators=100, score=0.604, total=   1.4s\n",
      "[CV] cv=3, gamma=0.1, learning_rate=0.01, max_depth=8, n_estimators=100 \n",
      "[CV]  cv=3, gamma=0.1, learning_rate=0.01, max_depth=8, n_estimators=100, score=0.604, total=   1.4s\n",
      "[CV] cv=3, gamma=0.1, learning_rate=0.01, max_depth=8, n_estimators=100 \n",
      "[CV]  cv=3, gamma=0.1, learning_rate=0.01, max_depth=8, n_estimators=100, score=0.567, total=   1.4s\n",
      "[CV] cv=3, gamma=0.1, learning_rate=0.01, max_depth=10, n_estimators=100 \n",
      "[CV]  cv=3, gamma=0.1, learning_rate=0.01, max_depth=10, n_estimators=100, score=0.626, total=   1.8s\n",
      "[CV] cv=3, gamma=0.1, learning_rate=0.01, max_depth=10, n_estimators=100 \n",
      "[CV]  cv=3, gamma=0.1, learning_rate=0.01, max_depth=10, n_estimators=100, score=0.620, total=   1.8s\n",
      "[CV] cv=3, gamma=0.1, learning_rate=0.01, max_depth=10, n_estimators=100 \n",
      "[CV]  cv=3, gamma=0.1, learning_rate=0.01, max_depth=10, n_estimators=100, score=0.574, total=   1.8s\n",
      "[CV] cv=3, gamma=0.1, learning_rate=0.01, max_depth=15, n_estimators=100 \n",
      "[CV]  cv=3, gamma=0.1, learning_rate=0.01, max_depth=15, n_estimators=100, score=0.619, total=   2.3s\n",
      "[CV] cv=3, gamma=0.1, learning_rate=0.01, max_depth=15, n_estimators=100 \n",
      "[CV]  cv=3, gamma=0.1, learning_rate=0.01, max_depth=15, n_estimators=100, score=0.603, total=   2.4s\n",
      "[CV] cv=3, gamma=0.1, learning_rate=0.01, max_depth=15, n_estimators=100 \n",
      "[CV]  cv=3, gamma=0.1, learning_rate=0.01, max_depth=15, n_estimators=100, score=0.574, total=   2.3s\n",
      "[CV] cv=3, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=100 \n",
      "[CV]  cv=3, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=100, score=0.636, total=   1.3s\n",
      "[CV] cv=3, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=100 \n",
      "[CV]  cv=3, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=100, score=0.631, total=   1.3s\n",
      "[CV] cv=3, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=100 \n",
      "[CV]  cv=3, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=100, score=0.588, total=   1.3s\n",
      "[CV] cv=3, gamma=0.1, learning_rate=0.1, max_depth=10, n_estimators=100 \n",
      "[CV]  cv=3, gamma=0.1, learning_rate=0.1, max_depth=10, n_estimators=100, score=0.651, total=   1.6s\n",
      "[CV] cv=3, gamma=0.1, learning_rate=0.1, max_depth=10, n_estimators=100 \n",
      "[CV]  cv=3, gamma=0.1, learning_rate=0.1, max_depth=10, n_estimators=100, score=0.633, total=   1.6s\n",
      "[CV] cv=3, gamma=0.1, learning_rate=0.1, max_depth=10, n_estimators=100 \n",
      "[CV]  cv=3, gamma=0.1, learning_rate=0.1, max_depth=10, n_estimators=100, score=0.585, total=   1.5s\n",
      "[CV] cv=3, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=100 \n",
      "[CV]  cv=3, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=100, score=0.652, total=   2.0s\n",
      "[CV] cv=3, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=100 \n",
      "[CV]  cv=3, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=100, score=0.636, total=   2.1s\n",
      "[CV] cv=3, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=100 \n",
      "[CV]  cv=3, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=100, score=0.589, total=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise',\n",
       "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=1, cv=3, eta=0.2, gamma=0,\n",
       "                                     learning_rate=0.1, max_delta_step=0,\n",
       "                                     max_depth=4, min_child_weight=1,\n",
       "                                     missing=None, n_estimators=1000, n_jobs=-1,\n",
       "                                     nthread=-1, objective='binary:logistic',\n",
       "                                     random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "                                     scale_pos_weight=1, seed=42, silent=False,\n",
       "                                     subsample=1, verbosity=1),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'cv': [3], 'gamma': [0, 0.1],\n",
       "                         'learning_rate': [0.01, 0.1], 'max_depth': [8, 10, 15],\n",
       "                         'n_estimators': [100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.629991 using {'cv': 3, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.590369 with: {'cv': 3, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.605608 with: {'cv': 3, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.598598 with: {'cv': 3, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.626029 with: {'cv': 3, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.629991 with: {'cv': 3, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.626333 with: {'cv': 3, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.591588 with: {'cv': 3, 'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.606522 with: {'cv': 3, 'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.598598 with: {'cv': 3, 'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.618409 with: {'cv': 3, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.622981 with: {'cv': 3, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.625724 with: {'cv': 3, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (model_grid.best_score_, model_grid.best_params_))\n",
    "means = model_grid.cv_results_['mean_test_score']\n",
    "params = model_grid.cv_results_['params']\n",
    "for mean, param in zip(means, params):\n",
    "    print(\"%f with: %r\" % (mean, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, cv=3, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=-1,\n",
       "              nthread=-1, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42,\n",
       "              silent=False, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Создаю модель с лучшими параметрами:\n",
    "best_model = XGBClassifier(\n",
    "            seed=42,\n",
    "            #eta = 0.2,\n",
    "            n_estimators=100,\n",
    "            max_depth=10,\n",
    "            learning_rate=0.1,\n",
    "            objective='binary:logistic',\n",
    "            cv=3,\n",
    "            gamma=0, \n",
    "            missing=None, \n",
    "            nthread=-1,\n",
    "            silent=False,\n",
    "            n_jobs = -1       \n",
    "    )\n",
    "\n",
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set is  99.96952148735141\n",
      "Accuracy on test set is  66.17192331478046\n"
     ]
    }
   ],
   "source": [
    "# Оценка качества модели\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy on train set is \", metrics.accuracy_score(y_train, y_pred_train)*100)\n",
    "print(\"Accuracy on test set is \", metrics.accuracy_score(y_test, y_pred_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И я не очень понимаю, почему во время gridsearch score не превышал 0.65, зато если же взять модель с параметрами из gridsearch, то она на том же самом X_train, y_train выдает почти 100% acc. Куда девается 30% accuracy в гридсерче? \n",
    "\n",
    "И получается, что по гридсерчу - никакого переобучения нет, зато если запустить вручную проверку, то переобучение на лицо :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И можно смело упростить модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set is  82.71868332825359\n",
      "Accuracy on test set is  60.17316017316018\n"
     ]
    }
   ],
   "source": [
    "#Создаю модель с упрощенными параметрами:\n",
    "simple_model = XGBClassifier(\n",
    "            seed=42,\n",
    "            learning_rate = 0.1,\n",
    "            n_estimators=100,\n",
    "            max_depth=5,\n",
    "            cv=3,\n",
    "            gamma=0, \n",
    "            nthread=-1,\n",
    "            silent=False,       \n",
    "    )\n",
    "\n",
    "simple_model.fit(X_train, y_train)\n",
    "\n",
    "# Оценка качества модели\n",
    "y_pred_train_simple = simple_model.predict(X_train)\n",
    "\n",
    "y_pred_test_simple = simple_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy on train set is \", metrics.accuracy_score(y_train, y_pred_train_simple)*100)\n",
    "print(\"Accuracy on test set is \", metrics.accuracy_score(y_test, y_pred_test_simple)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3 56.476683937823836 53.370439084724794 \n",
      "\n",
      "1 4 58.85400792441329 54.483611626468765 \n",
      "\n",
      "1 5 62.26760134105456 55.287569573283854 \n",
      "\n",
      "1 6 65.34593111856142 53.865182436611 \n",
      "\n",
      "1 7 69.85675099055166 54.112554112554115 \n",
      "\n",
      "1 8 74.15422127400183 55.22572665429808 \n",
      "\n",
      "1 9 76.40963120999696 54.916512059369204 \n",
      "\n",
      "1 10 80.15848826577263 56.4625850340136 \n",
      "\n",
      "1 11 83.05394696738799 56.95732838589982 \n",
      "\n",
      "1 12 84.91313623895154 57.45207173778603 \n",
      "\n",
      "1 13 85.91892715635477 56.77179962894249 \n",
      "\n",
      "1 14 86.98567509905517 57.32838589981447 \n",
      "\n",
      "6 3 56.87290460225542 53.555967841682126 \n",
      "\n",
      "6 4 59.76836330387078 53.98886827458256 \n",
      "\n",
      "6 5 64.18774763791527 55.04019789734076 \n",
      "\n",
      "6 6 68.85096007314843 56.153370439084725 \n",
      "\n",
      "6 7 74.61139896373057 57.14285714285714 \n",
      "\n",
      "6 8 79.1526973483694 57.7612863327149 \n",
      "\n",
      "6 9 85.1569643401402 59.0599876314162 \n",
      "\n",
      "6 10 88.78390734532154 60.544217687074834 \n",
      "\n",
      "6 11 91.58793050899116 61.16264687693259 \n",
      "\n",
      "6 12 93.1118561414203 61.6573902288188 \n",
      "\n",
      "6 13 94.39195367266078 61.224489795918366 \n",
      "\n",
      "6 14 95.18439500152392 62.27581941867656 \n",
      "\n",
      "11 3 57.08625419079549 52.81385281385281 \n",
      "\n",
      "11 4 60.80463273392258 53.80333951762524 \n",
      "\n",
      "11 5 65.10210301737274 55.163883735312304 \n",
      "\n",
      "11 6 71.0149344711978 56.58627087198516 \n",
      "\n",
      "11 7 76.68393782383419 58.13234384662957 \n",
      "\n",
      "11 8 83.32825358122523 59.36920222634509 \n",
      "\n",
      "11 9 88.69247180737581 60.3586889301175 \n",
      "\n",
      "11 10 92.28893629990857 61.34817563388992 \n",
      "\n",
      "11 11 94.27003962206645 61.71923314780457 \n",
      "\n",
      "11 12 95.64157269125266 62.77056277056276 \n",
      "\n",
      "11 13 96.76927765925024 62.708719851577 \n",
      "\n",
      "11 14 96.9826272477903 62.77056277056276 \n",
      "\n",
      "16 3 57.87869551965864 53.865182436611 \n",
      "\n",
      "16 4 61.71898811338007 54.73098330241187 \n",
      "\n",
      "16 5 66.99177080158488 55.84415584415584 \n",
      "\n",
      "16 6 72.38646754038402 58.13234384662957 \n",
      "\n",
      "16 7 79.36604693690947 58.56524427952999 \n",
      "\n",
      "16 8 84.69978665041145 60.235003092145945 \n",
      "\n",
      "16 9 90.67357512953367 61.100803957946816 \n",
      "\n",
      "16 10 94.11764705882352 61.904761904761905 \n",
      "\n",
      "16 11 95.42822310271258 62.09029066171924 \n",
      "\n",
      "16 12 96.89119170984456 63.017934446505876 \n",
      "\n",
      "16 13 97.83602560195062 62.708719851577 \n",
      "\n",
      "16 14 98.32368180432795 63.07977736549165 \n",
      "\n",
      "21 3 58.06156659555014 53.98886827458256 \n",
      "\n",
      "21 4 62.75525754343189 55.41125541125541 \n",
      "\n",
      "21 5 68.11947576958245 56.77179962894249 \n",
      "\n",
      "21 6 74.0323072234075 58.62708719851577 \n",
      "\n",
      "21 7 81.56049984760743 59.554730983302406 \n",
      "\n",
      "21 8 87.38189576348674 60.915275200989484 \n",
      "\n",
      "21 9 92.53276440109723 61.84291898577613 \n",
      "\n",
      "21 10 95.79396525449559 63.63636363636363 \n",
      "\n",
      "21 11 97.04358427308748 63.388991960420526 \n",
      "\n",
      "21 12 98.17128924108503 64.0074211502783 \n",
      "\n",
      "21 13 98.7808594940567 64.06926406926407 \n",
      "\n",
      "21 14 99.23803718378544 63.698206555349415 \n",
      "\n",
      "26 3 59.00640048765621 54.54545454545454 \n",
      "\n",
      "26 4 64.24870466321244 55.41125541125541 \n",
      "\n",
      "26 5 69.64340140201159 57.63760049474336 \n",
      "\n",
      "26 6 75.98293203291679 58.87445887445888 \n",
      "\n",
      "26 7 83.02346845473942 60.17316017316018 \n",
      "\n",
      "26 8 89.11917098445595 61.53370439084724 \n",
      "\n",
      "26 9 94.14812557147211 62.708719851577 \n",
      "\n",
      "26 10 97.01310576043889 64.56400742115028 \n",
      "\n",
      "26 11 98.26272477903079 64.13110698824984 \n",
      "\n",
      "26 12 98.96373056994818 64.7495361781076 \n",
      "\n",
      "26 13 99.26851569643401 64.0074211502783 \n",
      "\n",
      "26 14 99.4513867723255 64.62585034013605 \n",
      "\n",
      "31 3 60.073148430356596 54.85466914038343 \n",
      "\n",
      "31 4 64.98018896677841 55.163883735312304 \n",
      "\n",
      "31 5 71.0149344711978 57.57575757575758 \n",
      "\n",
      "31 6 77.14111551356294 59.43104514533086 \n",
      "\n",
      "31 7 84.02925937214263 60.97711811997526 \n",
      "\n",
      "31 8 90.76501066747943 62.52319109461967 \n",
      "\n",
      "31 9 95.36726607741542 63.388991960420526 \n",
      "\n",
      "31 10 98.11033221578786 64.7495361781076 \n",
      "\n",
      "31 11 98.9332520572996 64.44032158317873 \n",
      "\n",
      "31 12 99.35995123437976 65.3061224489796 \n",
      "\n",
      "31 13 99.48186528497409 65.49165120593692 \n",
      "\n",
      "31 14 99.69521487351417 64.44032158317873 \n",
      "\n",
      "36 3 61.26181042365133 54.85466914038343 \n",
      "\n",
      "36 4 66.22980798537031 56.58627087198516 \n",
      "\n",
      "36 5 72.41694605303262 58.19418676561534 \n",
      "\n",
      "36 6 78.451691557452 59.80210265924551 \n",
      "\n",
      "36 7 85.49222797927462 60.60606060606061 \n",
      "\n",
      "36 8 92.07558671136849 62.956091527520094 \n",
      "\n",
      "36 9 96.52544955806157 63.88373531230675 \n",
      "\n",
      "36 10 98.44559585492227 64.31663574520718 \n",
      "\n",
      "36 11 99.14660164583968 64.5021645021645 \n",
      "\n",
      "36 12 99.63425784821702 65.42980828695114 \n",
      "\n",
      "36 13 99.72569338616275 65.42980828695114 \n",
      "\n",
      "36 14 99.8171289241085 64.81137909709338 \n",
      "\n",
      "41 3 61.71898811338007 54.97835497835498 \n",
      "\n",
      "41 4 67.1136848521792 56.400742115027825 \n",
      "\n",
      "41 5 73.483693995733 57.82312925170068 \n",
      "\n",
      "41 6 80.40231636696129 60.42053184910328 \n",
      "\n",
      "41 7 87.22950320024383 61.28633271490415 \n",
      "\n",
      "41 8 93.0813776287717 63.141620284477426 \n",
      "\n",
      "41 9 97.13501981103322 64.19294990723562 \n",
      "\n",
      "41 10 98.44559585492227 64.7495361781076 \n",
      "\n",
      "41 11 99.4513867723255 65.42980828695114 \n",
      "\n",
      "41 12 99.8171289241085 65.42980828695114 \n",
      "\n",
      "41 13 99.84760743675709 65.67717996289424 \n",
      "\n",
      "41 14 99.87808594940567 65.24427952999382 \n",
      "\n",
      "46 3 62.541907954891805 55.10204081632652 \n",
      "\n",
      "46 4 68.0280402316367 56.153370439084725 \n",
      "\n",
      "46 5 74.24565681194758 57.69944341372912 \n",
      "\n",
      "46 6 81.86528497409327 60.544217687074834 \n",
      "\n",
      "46 7 88.93629990856446 61.96660482374769 \n",
      "\n",
      "46 8 94.20908259676928 64.0074211502783 \n",
      "\n",
      "46 9 97.74459006400488 64.62585034013605 \n",
      "\n",
      "46 10 98.7503809814081 64.99690785405072 \n",
      "\n",
      "46 11 99.66473636086559 65.49165120593692 \n",
      "\n",
      "46 12 99.84760743675709 64.81137909709338 \n",
      "\n",
      "46 13 99.93904297470283 65.36796536796537 \n",
      "\n",
      "46 14 99.90856446205424 65.3061224489796 \n",
      "\n",
      "51 3 63.730569948186535 55.65862708719852 \n",
      "\n",
      "51 4 68.79000304785127 56.400742115027825 \n",
      "\n",
      "51 5 75.40384029259373 58.317872603586885 \n",
      "\n",
      "51 6 83.14538250533374 61.53370439084724 \n",
      "\n",
      "51 7 90.03352636391344 62.39950525664811 \n",
      "\n",
      "51 8 95.5806156659555 64.37847866419295 \n",
      "\n",
      "51 9 98.14081072843646 64.93506493506493 \n",
      "\n",
      "51 10 99.05516610789394 65.42980828695114 \n",
      "\n",
      "51 11 99.78665041145992 65.98639455782312 \n",
      "\n",
      "51 12 99.90856446205424 65.24427952999382 \n",
      "\n",
      "51 13 99.96952148735141 65.18243661100804 \n",
      "\n",
      "51 14 99.96952148735141 65.18243661100804 \n",
      "\n",
      "56 3 64.1572691252667 55.96784168212739 \n",
      "\n",
      "56 4 69.43005181347151 56.27705627705628 \n",
      "\n",
      "56 5 76.37915269734837 59.24551638837353 \n",
      "\n",
      "56 6 84.15117342273697 61.100803957946816 \n",
      "\n",
      "56 7 90.94788174337093 62.39950525664811 \n",
      "\n",
      "56 8 96.19018591892716 64.25479282622139 \n",
      "\n",
      "56 9 98.47607436757086 65.42980828695114 \n",
      "\n",
      "56 10 99.26851569643401 65.42980828695114 \n",
      "\n",
      "56 11 99.8171289241085 65.67717996289424 \n",
      "\n",
      "56 12 99.93904297470283 65.0587507730365 \n",
      "\n",
      "56 13 99.96952148735141 65.3061224489796 \n",
      "\n",
      "56 14 99.96952148735141 64.87322201607915 \n",
      "\n",
      "61 3 64.644925327644 56.09152752009895 \n",
      "\n",
      "61 4 69.97866504114599 56.77179962894249 \n",
      "\n",
      "61 5 77.44590064004878 59.307359307359306 \n",
      "\n",
      "61 6 84.97409326424871 60.97711811997526 \n",
      "\n",
      "61 7 91.61840902163975 62.46134817563389 \n",
      "\n",
      "61 8 96.52544955806157 64.7495361781076 \n",
      "\n",
      "61 9 98.68942395611094 65.61533704390847 \n",
      "\n",
      "61 10 99.35995123437976 65.73902288188003 \n",
      "\n",
      "61 11 99.84760743675709 65.61533704390847 \n",
      "\n",
      "61 12 99.96952148735141 65.3061224489796 \n",
      "\n",
      "61 13 99.96952148735141 65.0587507730365 \n",
      "\n",
      "61 14 99.96952148735141 65.24427952999382 \n",
      "\n",
      "66 3 65.28497409326425 56.153370439084725 \n",
      "\n",
      "66 4 70.61871380676624 56.89548546691404 \n",
      "\n",
      "66 5 78.17738494361475 58.93630179344464 \n",
      "\n",
      "66 6 86.19323377019201 60.85343228200371 \n",
      "\n",
      "66 7 92.62419993904297 62.832405689548544 \n",
      "\n",
      "66 8 97.10454129838465 64.87322201607915 \n",
      "\n",
      "66 9 98.84181651935386 65.86270871985158 \n",
      "\n",
      "66 10 99.60377933556842 65.67717996289424 \n",
      "\n",
      "66 11 99.90856446205424 65.67717996289424 \n",
      "\n",
      "66 12 99.96952148735141 65.42980828695114 \n",
      "\n",
      "66 13 99.96952148735141 65.61533704390847 \n",
      "\n",
      "66 14 100.0 65.5534941249227 \n",
      "\n",
      "71 3 65.49832368180432 56.27705627705628 \n",
      "\n",
      "71 4 71.28924108503504 57.266542980828696 \n",
      "\n",
      "71 5 78.9698262724779 58.998144712430424 \n",
      "\n",
      "71 6 87.16854617494666 62.09029066171924 \n",
      "\n",
      "71 7 93.53855531850046 63.4508348794063 \n",
      "\n",
      "71 8 97.59219750076197 64.62585034013605 \n",
      "\n",
      "71 9 99.05516610789394 65.73902288188003 \n",
      "\n",
      "71 10 99.60377933556842 65.98639455782312 \n",
      "\n",
      "71 11 99.93904297470283 65.73902288188003 \n",
      "\n",
      "71 12 99.96952148735141 65.12059369202227 \n",
      "\n",
      "71 13 100.0 65.36796536796537 \n",
      "\n",
      "71 14 100.0 65.42980828695114 \n",
      "\n",
      "76 3 66.10789393477599 56.709956709956714 \n",
      "\n",
      "76 4 72.0816824138982 57.204700061842914 \n",
      "\n",
      "76 5 79.45748247485523 59.36920222634509 \n",
      "\n",
      "76 6 87.4733313014325 62.152133580705005 \n",
      "\n",
      "76 7 94.05669003352637 63.698206555349415 \n",
      "\n",
      "76 8 97.95793965254495 65.12059369202227 \n",
      "\n",
      "76 9 99.23803718378544 65.49165120593692 \n",
      "\n",
      "76 10 99.75617189881135 65.98639455782312 \n",
      "\n",
      "76 11 99.96952148735141 66.04823747680891 \n",
      "\n",
      "76 12 99.96952148735141 64.7495361781076 \n",
      "\n",
      "76 13 100.0 65.24427952999382 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76 14 100.0 65.18243661100804 \n",
      "\n",
      "81 3 66.4431575739104 57.14285714285714 \n",
      "\n",
      "81 4 72.99603779335568 58.00865800865801 \n",
      "\n",
      "81 5 80.46327339225846 59.43104514533086 \n",
      "\n",
      "81 6 88.44864370618714 61.84291898577613 \n",
      "\n",
      "81 7 94.6967387991466 63.821892393320965 \n",
      "\n",
      "81 8 98.14081072843646 65.0587507730365 \n",
      "\n",
      "81 9 99.39042974702834 66.54298082869512 \n",
      "\n",
      "81 10 99.90856446205424 65.98639455782312 \n",
      "\n",
      "81 11 100.0 65.73902288188003 \n",
      "\n",
      "81 12 100.0 65.0587507730365 \n",
      "\n",
      "81 13 100.0 65.3061224489796 \n",
      "\n",
      "81 14 100.0 65.12059369202227 \n",
      "\n",
      "86 3 66.68698567509905 56.95732838589982 \n",
      "\n",
      "86 4 73.3313014324901 57.7612863327149 \n",
      "\n",
      "86 5 81.01188661993295 59.863945578231295 \n",
      "\n",
      "86 6 89.45443462359037 62.02844774273346 \n",
      "\n",
      "86 7 95.27583053946968 64.19294990723562 \n",
      "\n",
      "86 8 98.41511734227369 65.0587507730365 \n",
      "\n",
      "86 9 99.48186528497409 66.11008039579468 \n",
      "\n",
      "86 10 99.93904297470283 66.04823747680891 \n",
      "\n",
      "86 11 100.0 65.61533704390847 \n",
      "\n",
      "86 12 100.0 64.93506493506493 \n",
      "\n",
      "86 13 100.0 65.18243661100804 \n",
      "\n",
      "86 14 100.0 65.36796536796537 \n",
      "\n",
      "91 3 67.14416336482779 57.14285714285714 \n",
      "\n",
      "91 4 73.69704358427309 57.69944341372912 \n",
      "\n",
      "91 5 81.74337092349894 60.42053184910328 \n",
      "\n",
      "91 6 90.1249619018592 62.52319109461967 \n",
      "\n",
      "91 7 95.5806156659555 64.0074211502783 \n",
      "\n",
      "91 8 98.50655288021945 64.7495361781076 \n",
      "\n",
      "91 9 99.69521487351417 66.17192331478046 \n",
      "\n",
      "91 10 99.96952148735141 66.17192331478046 \n",
      "\n",
      "91 11 100.0 65.67717996289424 \n",
      "\n",
      "91 12 100.0 65.0587507730365 \n",
      "\n",
      "91 13 100.0 65.36796536796537 \n",
      "\n",
      "91 14 100.0 65.36796536796537 \n",
      "\n",
      "96 3 67.41846997866504 56.58627087198516 \n",
      "\n",
      "96 4 74.30661383724474 58.13234384662957 \n",
      "\n",
      "96 5 82.29198415117342 60.42053184910328 \n",
      "\n",
      "96 6 90.82596769277659 62.27581941867656 \n",
      "\n",
      "96 7 95.82444376714416 64.31663574520718 \n",
      "\n",
      "96 8 98.84181651935386 64.56400742115028 \n",
      "\n",
      "96 9 99.72569338616275 66.17192331478046 \n",
      "\n",
      "96 10 99.96952148735141 66.17192331478046 \n",
      "\n",
      "96 11 100.0 65.73902288188003 \n",
      "\n",
      "96 12 100.0 64.87322201607915 \n",
      "\n",
      "96 13 100.0 65.12059369202227 \n",
      "\n",
      "96 14 100.0 65.42980828695114 \n",
      "\n",
      "101 3 67.81469064309663 56.33889919604206 \n",
      "\n",
      "101 4 74.64187747637915 58.44155844155844 \n",
      "\n",
      "101 5 82.99298994209082 60.1113172541744 \n",
      "\n",
      "101 6 91.61840902163975 62.64687693259122 \n",
      "\n",
      "101 7 96.06827186833283 64.19294990723562 \n",
      "\n",
      "101 8 98.96373056994818 64.68769325912183 \n",
      "\n",
      "101 9 99.72569338616275 66.04823747680891 \n",
      "\n",
      "101 10 99.96952148735141 66.17192331478046 \n",
      "\n",
      "101 11 100.0 65.86270871985158 \n",
      "\n",
      "101 12 100.0 64.68769325912183 \n",
      "\n",
      "101 13 100.0 65.0587507730365 \n",
      "\n",
      "101 14 100.0 65.80086580086581 \n",
      "\n",
      "106 3 68.05851874428528 57.01917130488559 \n",
      "\n",
      "106 4 75.40384029259373 58.62708719851577 \n",
      "\n",
      "106 5 83.63303870771107 60.17316017316018 \n",
      "\n",
      "106 6 92.28893629990857 62.77056277056276 \n",
      "\n",
      "106 7 96.3120999695215 64.25479282622139 \n",
      "\n",
      "106 8 99.11612313319111 64.68769325912183 \n",
      "\n",
      "106 9 99.8171289241085 65.80086580086581 \n",
      "\n",
      "106 10 99.96952148735141 66.04823747680891 \n",
      "\n",
      "106 11 100.0 65.92455163883734 \n",
      "\n",
      "106 12 100.0 64.44032158317873 \n",
      "\n",
      "106 13 100.0 65.18243661100804 \n",
      "\n",
      "106 14 100.0 65.73902288188003 \n",
      "\n",
      "111 3 68.45473940871686 56.89548546691404 \n",
      "\n",
      "111 4 75.61718988113381 58.44155844155844 \n",
      "\n",
      "111 5 84.0902163974398 60.235003092145945 \n",
      "\n",
      "111 6 92.9289850655288 63.07977736549165 \n",
      "\n",
      "111 7 96.92167022249313 64.5021645021645 \n",
      "\n",
      "111 8 99.26851569643401 64.93506493506493 \n",
      "\n",
      "111 9 99.84760743675709 65.80086580086581 \n",
      "\n",
      "111 10 99.96952148735141 65.98639455782312 \n",
      "\n",
      "111 11 100.0 65.80086580086581 \n",
      "\n",
      "111 12 100.0 65.12059369202227 \n",
      "\n",
      "111 13 100.0 65.5534941249227 \n",
      "\n",
      "111 14 100.0 65.80086580086581 \n",
      "\n",
      "116 3 68.45473940871686 57.01917130488559 \n",
      "\n",
      "116 4 76.19628162145688 58.93630179344464 \n",
      "\n",
      "116 5 84.97409326424871 60.235003092145945 \n",
      "\n",
      "116 6 93.56903383114904 63.141620284477426 \n",
      "\n",
      "116 7 97.50076196281621 64.7495361781076 \n",
      "\n",
      "116 8 99.32947272173118 64.99690785405072 \n",
      "\n",
      "116 9 99.90856446205424 65.86270871985158 \n",
      "\n",
      "116 10 99.96952148735141 66.17192331478046 \n",
      "\n",
      "116 11 100.0 65.73902288188003 \n",
      "\n",
      "116 12 100.0 64.87322201607915 \n",
      "\n",
      "116 13 100.0 65.36796536796537 \n",
      "\n",
      "116 14 100.0 65.73902288188003 \n",
      "\n",
      "121 3 68.57665345931119 57.01917130488559 \n",
      "\n",
      "121 4 76.3181956720512 58.68893011750155 \n",
      "\n",
      "121 5 85.40079244132886 60.544217687074834 \n",
      "\n",
      "121 6 93.90429747028345 63.698206555349415 \n",
      "\n",
      "121 7 97.95793965254495 64.81137909709338 \n",
      "\n",
      "121 8 99.51234379762268 65.42980828695114 \n",
      "\n",
      "121 9 99.90856446205424 65.92455163883734 \n",
      "\n",
      "121 10 100.0 66.17192331478046 \n",
      "\n",
      "121 11 100.0 65.5534941249227 \n",
      "\n",
      "121 12 100.0 65.12059369202227 \n",
      "\n",
      "121 13 100.0 65.49165120593692 \n",
      "\n",
      "121 14 100.0 65.73902288188003 \n",
      "\n",
      "126 3 68.94239561109417 57.266542980828696 \n",
      "\n",
      "126 4 76.68393782383419 58.93630179344464 \n",
      "\n",
      "126 5 86.10179823224627 61.100803957946816 \n",
      "\n",
      "126 6 94.36147516001219 63.63636363636363 \n",
      "\n",
      "126 7 98.20176775373362 64.93506493506493 \n",
      "\n",
      "126 8 99.57330082291985 65.67717996289424 \n",
      "\n",
      "126 9 99.96952148735141 65.73902288188003 \n",
      "\n",
      "126 10 100.0 66.41929499072357 \n",
      "\n",
      "126 11 100.0 65.73902288188003 \n",
      "\n",
      "126 12 100.0 65.12059369202227 \n",
      "\n",
      "126 13 100.0 65.3061224489796 \n",
      "\n",
      "126 14 100.0 65.98639455782312 \n",
      "\n",
      "131 3 69.27765925022858 57.32838589981447 \n",
      "\n",
      "131 4 76.92776592502287 59.183673469387756 \n",
      "\n",
      "131 5 86.43706187138068 61.53370439084724 \n",
      "\n",
      "131 6 94.75769582444377 63.76004947433519 \n",
      "\n",
      "131 7 98.35416031697653 64.68769325912183 \n",
      "\n",
      "131 8 99.60377933556842 65.67717996289424 \n",
      "\n",
      "131 9 100.0 65.80086580086581 \n",
      "\n",
      "131 10 100.0 66.41929499072357 \n",
      "\n",
      "131 11 100.0 65.61533704390847 \n",
      "\n",
      "131 12 100.0 65.36796536796537 \n",
      "\n",
      "131 13 100.0 65.24427952999382 \n",
      "\n",
      "131 14 100.0 65.86270871985158 \n",
      "\n",
      "136 3 69.64340140201159 57.32838589981447 \n",
      "\n",
      "136 4 77.59829320329168 58.998144712430424 \n",
      "\n",
      "136 5 86.71136848521792 61.34817563388992 \n",
      "\n",
      "136 6 95.0624809509296 63.94557823129252 \n",
      "\n",
      "136 7 98.65894544346236 64.62585034013605 \n",
      "\n",
      "136 8 99.60377933556842 65.86270871985158 \n",
      "\n",
      "136 9 100.0 65.67717996289424 \n",
      "\n",
      "136 10 100.0 66.48113790970935 \n",
      "\n",
      "136 11 100.0 65.61533704390847 \n",
      "\n",
      "136 12 100.0 65.5534941249227 \n",
      "\n",
      "136 13 100.0 65.0587507730365 \n",
      "\n",
      "136 14 100.0 65.67717996289424 \n",
      "\n",
      "141 3 70.10057909174033 57.57575757575758 \n",
      "\n",
      "141 4 78.14690643096617 59.121830550401974 \n",
      "\n",
      "141 5 87.16854617494666 61.16264687693259 \n",
      "\n",
      "141 6 95.2453520268211 64.13110698824984 \n",
      "\n",
      "141 7 98.87229503200243 64.81137909709338 \n",
      "\n",
      "141 8 99.60377933556842 65.98639455782312 \n",
      "\n",
      "141 9 100.0 65.49165120593692 \n",
      "\n",
      "141 10 100.0 66.35745207173778 \n",
      "\n",
      "141 11 100.0 65.98639455782312 \n",
      "\n",
      "141 12 100.0 65.3061224489796 \n",
      "\n",
      "141 13 100.0 65.12059369202227 \n",
      "\n",
      "141 14 100.0 66.04823747680891 \n",
      "\n",
      "146 3 70.3139286802804 58.00865800865801 \n",
      "\n",
      "146 4 78.75647668393782 59.121830550401974 \n",
      "\n",
      "146 5 87.77811642791832 61.34817563388992 \n",
      "\n",
      "146 6 95.51965864065834 64.13110698824984 \n",
      "\n",
      "146 7 99.11612313319111 64.93506493506493 \n",
      "\n",
      "146 8 99.60377933556842 66.11008039579468 \n",
      "\n",
      "146 9 100.0 65.73902288188003 \n",
      "\n",
      "146 10 100.0 66.48113790970935 \n",
      "\n",
      "146 11 100.0 65.86270871985158 \n",
      "\n",
      "146 12 100.0 65.36796536796537 \n",
      "\n",
      "146 13 100.0 65.3061224489796 \n",
      "\n",
      "146 14 100.0 65.80086580086581 \n",
      "\n",
      "151 3 70.28345016763183 57.88497217068645 \n",
      "\n",
      "151 4 79.27461139896373 59.307359307359306 \n",
      "\n",
      "151 5 88.41816519353856 61.781076066790355 \n",
      "\n",
      "151 6 96.00731484303566 63.821892393320965 \n",
      "\n",
      "151 7 99.20755867113685 65.3061224489796 \n",
      "\n",
      "151 8 99.66473636086559 66.04823747680891 \n",
      "\n",
      "151 9 100.0 65.73902288188003 \n",
      "\n",
      "151 10 100.0 66.29560915275201 \n",
      "\n",
      "151 11 100.0 65.80086580086581 \n",
      "\n",
      "151 12 100.0 65.12059369202227 \n",
      "\n",
      "151 13 100.0 65.24427952999382 \n",
      "\n",
      "151 14 100.0 65.5534941249227 \n",
      "\n",
      "156 3 70.64919231941481 58.070500927643785 \n",
      "\n",
      "156 4 79.64035355074672 59.43104514533086 \n",
      "\n",
      "156 5 89.02773544651022 61.904761904761905 \n",
      "\n",
      "156 6 96.19018591892716 64.25479282622139 \n",
      "\n",
      "156 7 99.32947272173118 65.0587507730365 \n",
      "\n",
      "156 8 99.75617189881135 65.92455163883734 \n",
      "\n",
      "156 9 100.0 65.61533704390847 \n",
      "\n",
      "156 10 100.0 66.35745207173778 \n",
      "\n",
      "156 11 100.0 65.61533704390847 \n",
      "\n",
      "156 12 100.0 65.24427952999382 \n",
      "\n",
      "156 13 100.0 65.24427952999382 \n",
      "\n",
      "156 14 100.0 65.49165120593692 \n",
      "\n",
      "161 3 71.16732703444072 58.070500927643785 \n",
      "\n",
      "161 4 80.18896677842122 59.36920222634509 \n",
      "\n",
      "161 5 89.42395611094179 61.96660482374769 \n",
      "\n",
      "161 6 96.37305699481865 64.37847866419295 \n",
      "\n",
      "161 7 99.4513867723255 65.3061224489796 \n",
      "\n",
      "161 8 99.8171289241085 65.98639455782312 \n",
      "\n",
      "161 9 100.0 65.49165120593692 \n",
      "\n",
      "161 10 100.0 66.23376623376623 \n",
      "\n",
      "161 11 100.0 65.49165120593692 \n",
      "\n",
      "161 12 100.0 65.42980828695114 \n",
      "\n",
      "161 13 100.0 65.36796536796537 \n",
      "\n",
      "161 14 100.0 65.49165120593692 \n",
      "\n",
      "166 3 71.44163364827797 58.13234384662957 \n",
      "\n",
      "166 4 80.67662298079854 59.61657390228818 \n",
      "\n",
      "166 5 89.85065528802194 62.46134817563389 \n",
      "\n",
      "166 6 96.73879914660165 64.56400742115028 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166 7 99.48186528497409 65.42980828695114 \n",
      "\n",
      "166 8 99.8171289241085 65.92455163883734 \n",
      "\n",
      "166 9 100.0 65.36796536796537 \n",
      "\n",
      "166 10 100.0 66.17192331478046 \n",
      "\n",
      "166 11 100.0 65.73902288188003 \n",
      "\n",
      "166 12 100.0 65.42980828695114 \n",
      "\n",
      "166 13 100.0 64.87322201607915 \n",
      "\n",
      "166 14 100.0 65.49165120593692 \n",
      "\n",
      "171 3 71.53306918622371 57.88497217068645 \n",
      "\n",
      "171 4 80.95092959463578 59.92578849721707 \n",
      "\n",
      "171 5 90.27735446510209 62.21397649969078 \n",
      "\n",
      "171 6 96.95214873514173 64.81137909709338 \n",
      "\n",
      "171 7 99.51234379762268 65.18243661100804 \n",
      "\n",
      "171 8 99.84760743675709 65.92455163883734 \n",
      "\n",
      "171 9 100.0 65.5534941249227 \n",
      "\n",
      "171 10 100.0 66.17192331478046 \n",
      "\n",
      "171 11 100.0 65.61533704390847 \n",
      "\n",
      "171 12 100.0 65.49165120593692 \n",
      "\n",
      "171 13 100.0 65.24427952999382 \n",
      "\n",
      "171 14 100.0 65.61533704390847 \n",
      "\n",
      "176 3 71.74641877476378 57.7612863327149 \n",
      "\n",
      "176 4 81.65193538555319 60.235003092145945 \n",
      "\n",
      "176 5 90.6430966168851 62.27581941867656 \n",
      "\n",
      "176 6 97.37884791222189 65.42980828695114 \n",
      "\n",
      "176 7 99.51234379762268 65.49165120593692 \n",
      "\n",
      "176 8 99.87808594940567 65.5534941249227 \n",
      "\n",
      "176 9 100.0 65.80086580086581 \n",
      "\n",
      "176 10 100.0 66.17192331478046 \n",
      "\n",
      "176 11 100.0 65.67717996289424 \n",
      "\n",
      "176 12 100.0 65.61533704390847 \n",
      "\n",
      "176 13 100.0 65.0587507730365 \n",
      "\n",
      "176 14 100.0 65.5534941249227 \n",
      "\n",
      "181 3 72.11216092654679 57.5139146567718 \n",
      "\n",
      "181 4 81.92624199939043 60.42053184910328 \n",
      "\n",
      "181 5 91.03931728131667 62.585034013605444 \n",
      "\n",
      "181 6 97.50076196281621 65.18243661100804 \n",
      "\n",
      "181 7 99.57330082291985 65.24427952999382 \n",
      "\n",
      "181 8 99.90856446205424 65.5534941249227 \n",
      "\n",
      "181 9 100.0 65.73902288188003 \n",
      "\n",
      "181 10 100.0 66.17192331478046 \n",
      "\n",
      "181 11 100.0 65.73902288188003 \n",
      "\n",
      "181 12 100.0 65.36796536796537 \n",
      "\n",
      "181 13 100.0 65.3061224489796 \n",
      "\n",
      "181 14 100.0 65.67717996289424 \n",
      "\n",
      "186 3 72.14263943919536 57.63760049474336 \n",
      "\n",
      "186 4 82.01767753733617 60.17316017316018 \n",
      "\n",
      "186 5 91.43553794574825 62.708719851577 \n",
      "\n",
      "186 6 97.62267601341054 65.0587507730365 \n",
      "\n",
      "186 7 99.63425784821702 65.3061224489796 \n",
      "\n",
      "186 8 99.90856446205424 65.98639455782312 \n",
      "\n",
      "186 9 100.0 65.61533704390847 \n",
      "\n",
      "186 10 100.0 66.41929499072357 \n",
      "\n",
      "186 11 100.0 65.73902288188003 \n",
      "\n",
      "186 12 100.0 65.49165120593692 \n",
      "\n",
      "186 13 100.0 65.3061224489796 \n",
      "\n",
      "186 14 100.0 65.67717996289424 \n",
      "\n",
      "191 3 72.41694605303262 57.7612863327149 \n",
      "\n",
      "191 4 82.59676927765925 60.29684601113172 \n",
      "\n",
      "191 5 91.89271563547699 62.708719851577 \n",
      "\n",
      "191 6 97.86650411459921 64.81137909709338 \n",
      "\n",
      "191 7 99.69521487351417 65.36796536796537 \n",
      "\n",
      "191 8 99.93904297470283 65.80086580086581 \n",
      "\n",
      "191 9 100.0 65.5534941249227 \n",
      "\n",
      "191 10 100.0 66.35745207173778 \n",
      "\n",
      "191 11 100.0 65.80086580086581 \n",
      "\n",
      "191 12 100.0 65.80086580086581 \n",
      "\n",
      "191 13 100.0 65.36796536796537 \n",
      "\n",
      "191 14 100.0 65.42980828695114 \n",
      "\n",
      "196 3 72.53886010362694 57.82312925170068 \n",
      "\n",
      "196 4 83.11490399268516 60.48237476808905 \n",
      "\n",
      "196 5 92.0451081987199 62.832405689548544 \n",
      "\n",
      "196 6 98.14081072843646 64.5021645021645 \n",
      "\n",
      "196 7 99.69521487351417 65.36796536796537 \n",
      "\n",
      "196 8 99.93904297470283 65.98639455782312 \n",
      "\n",
      "196 9 100.0 65.49165120593692 \n",
      "\n",
      "196 10 100.0 66.29560915275201 \n",
      "\n",
      "196 11 100.0 65.80086580086581 \n",
      "\n",
      "196 12 100.0 65.92455163883734 \n",
      "\n",
      "196 13 100.0 65.18243661100804 \n",
      "\n",
      "196 14 100.0 65.67717996289424 \n",
      "\n",
      "201 3 72.69125266686986 58.070500927643785 \n",
      "\n",
      "201 4 83.54160316976531 60.667903525046384 \n",
      "\n",
      "201 5 92.38037183785431 63.141620284477426 \n",
      "\n",
      "201 6 98.26272477903079 64.68769325912183 \n",
      "\n",
      "201 7 99.69521487351417 65.36796536796537 \n",
      "\n",
      "201 8 100.0 66.04823747680891 \n",
      "\n",
      "201 9 100.0 65.49165120593692 \n",
      "\n",
      "201 10 100.0 66.17192331478046 \n",
      "\n",
      "201 11 100.0 65.80086580086581 \n",
      "\n",
      "201 12 100.0 65.98639455782312 \n",
      "\n",
      "201 13 100.0 65.18243661100804 \n",
      "\n",
      "201 14 100.0 65.5534941249227 \n",
      "\n",
      "206 3 73.11795184395001 58.317872603586885 \n",
      "\n",
      "206 4 83.66351722035965 60.667903525046384 \n",
      "\n",
      "206 5 92.71563547698872 63.07977736549165 \n",
      "\n",
      "206 6 98.32368180432795 64.31663574520718 \n",
      "\n",
      "206 7 99.69521487351417 65.12059369202227 \n",
      "\n",
      "206 8 100.0 66.11008039579468 \n",
      "\n",
      "206 9 100.0 65.5534941249227 \n",
      "\n",
      "206 10 100.0 66.29560915275201 \n",
      "\n",
      "206 11 100.0 65.73902288188003 \n",
      "\n",
      "206 12 100.0 65.67717996289424 \n",
      "\n",
      "206 13 100.0 65.18243661100804 \n",
      "\n",
      "206 14 100.0 65.61533704390847 \n",
      "\n",
      "211 3 73.54465102103018 58.25602968460112 \n",
      "\n",
      "211 4 84.15117342273697 60.97711811997526 \n",
      "\n",
      "211 5 92.9289850655288 62.89424860853432 \n",
      "\n",
      "211 6 98.56750990551662 64.31663574520718 \n",
      "\n",
      "211 7 99.72569338616275 65.61533704390847 \n",
      "\n",
      "211 8 100.0 65.92455163883734 \n",
      "\n",
      "211 9 100.0 65.42980828695114 \n",
      "\n",
      "211 10 100.0 66.29560915275201 \n",
      "\n",
      "211 11 100.0 65.92455163883734 \n",
      "\n",
      "211 12 100.0 65.49165120593692 \n",
      "\n",
      "211 13 100.0 65.24427952999382 \n",
      "\n",
      "211 14 100.0 65.61533704390847 \n",
      "\n",
      "216 3 73.87991466016459 58.37971552257266 \n",
      "\n",
      "216 4 84.4559585492228 61.224489795918366 \n",
      "\n",
      "216 5 93.05089911612313 63.32714904143476 \n",
      "\n",
      "216 6 98.68942395611094 64.7495361781076 \n",
      "\n",
      "216 7 99.75617189881135 65.67717996289424 \n",
      "\n",
      "216 8 100.0 66.04823747680891 \n",
      "\n",
      "216 9 100.0 65.49165120593692 \n",
      "\n",
      "216 10 100.0 66.35745207173778 \n",
      "\n",
      "216 11 100.0 65.73902288188003 \n",
      "\n",
      "216 12 100.0 65.42980828695114 \n",
      "\n",
      "216 13 100.0 65.18243661100804 \n",
      "\n",
      "216 14 100.0 65.67717996289424 \n",
      "\n",
      "221 3 74.12374276135326 58.87445887445888 \n",
      "\n",
      "221 4 84.69978665041145 61.53370439084724 \n",
      "\n",
      "221 5 93.26424870466322 63.821892393320965 \n",
      "\n",
      "221 6 98.81133800670527 64.81137909709338 \n",
      "\n",
      "221 7 99.8171289241085 65.61533704390847 \n",
      "\n",
      "221 8 100.0 65.86270871985158 \n",
      "\n",
      "221 9 100.0 65.49165120593692 \n",
      "\n",
      "221 10 100.0 66.04823747680891 \n",
      "\n",
      "221 11 100.0 65.92455163883734 \n",
      "\n",
      "221 12 100.0 65.36796536796537 \n",
      "\n",
      "221 13 100.0 65.18243661100804 \n",
      "\n",
      "221 14 100.0 65.61533704390847 \n",
      "\n",
      "226 3 74.73331301432489 58.750773036487324 \n",
      "\n",
      "226 4 85.24839987808595 61.59554730983302 \n",
      "\n",
      "226 5 93.53855531850046 63.698206555349415 \n",
      "\n",
      "226 6 98.87229503200243 64.68769325912183 \n",
      "\n",
      "226 7 99.8171289241085 65.24427952999382 \n",
      "\n",
      "226 8 100.0 65.86270871985158 \n",
      "\n",
      "226 9 100.0 65.36796536796537 \n",
      "\n",
      "226 10 100.0 66.11008039579468 \n",
      "\n",
      "226 11 100.0 65.5534941249227 \n",
      "\n",
      "226 12 100.0 65.42980828695114 \n",
      "\n",
      "226 13 100.0 65.18243661100804 \n",
      "\n",
      "226 14 100.0 65.18243661100804 \n",
      "\n",
      "231 3 75.03809814081073 58.62708719851577 \n",
      "\n",
      "231 4 85.40079244132886 61.59554730983302 \n",
      "\n",
      "231 5 93.93477598293202 63.76004947433519 \n",
      "\n",
      "231 6 98.96373056994818 64.68769325912183 \n",
      "\n",
      "231 7 99.87808594940567 65.18243661100804 \n",
      "\n",
      "231 8 100.0 65.92455163883734 \n",
      "\n",
      "231 9 100.0 65.36796536796537 \n",
      "\n",
      "231 10 100.0 66.23376623376623 \n",
      "\n",
      "231 11 100.0 65.49165120593692 \n",
      "\n",
      "231 12 100.0 65.3061224489796 \n",
      "\n",
      "231 13 100.0 65.3061224489796 \n",
      "\n",
      "231 14 100.0 65.24427952999382 \n",
      "\n",
      "236 3 75.34288326729656 58.68893011750155 \n",
      "\n",
      "236 4 85.94940566900335 61.6573902288188 \n",
      "\n",
      "236 5 94.3309966473636 63.76004947433519 \n",
      "\n",
      "236 6 99.05516610789394 64.62585034013605 \n",
      "\n",
      "236 7 99.87808594940567 65.5534941249227 \n",
      "\n",
      "236 8 100.0 65.92455163883734 \n",
      "\n",
      "236 9 100.0 65.49165120593692 \n",
      "\n",
      "236 10 100.0 66.29560915275201 \n",
      "\n",
      "236 11 100.0 65.36796536796537 \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-164-db59232cb8a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         )\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0msimple_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m# Оценка качества модели\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[0;32m    730\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 732\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    734\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"objective\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[0;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[1;32m-> 1109\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m   1110\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_estimators = 1\n",
    "\n",
    "for n_estimators in range(1,500,5):\n",
    "    for max_depth in range(3,15,1):\n",
    "        simple_model = XGBClassifier(\n",
    "                seed = 42,\n",
    "                learning_rate = 0.1,\n",
    "                n_estimators = n_estimators,\n",
    "                max_depth = max_depth,\n",
    "                cv = 3,\n",
    "                gamma = 0, \n",
    "                nthread = -1,\n",
    "                silent = False,       \n",
    "        )\n",
    "\n",
    "        simple_model.fit(X_train, y_train)\n",
    "\n",
    "        # Оценка качества модели\n",
    "        y_pred_train_simple = simple_model.predict(X_train)\n",
    "        y_pred_test_simple = simple_model.predict(X_test)\n",
    "\n",
    "        #print(\"Accuracy on train set is \", metrics.accuracy_score(y_train, y_pred_train_simple)*100)\n",
    "        #print(\"Accuracy on test set is \", metrics.accuracy_score(y_test, y_pred_test_simple)*100)\n",
    "        \n",
    "        score_train = metrics.accuracy_score(y_train, y_pred_train_simple)*100\n",
    "        score_test = metrics.accuracy_score(y_test, y_pred_test_simple)*100\n",
    "        print(n_estimators, max_depth, score_train, score_test, \"\\n\")\n",
    "        if (score_test > max_score):\n",
    "            max_score = score_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.54298082869512\n"
     ]
    }
   ],
   "source": [
    "print(max_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перебором удалось найти параметры с максимальным скором на тесовой выборке = 66.54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
